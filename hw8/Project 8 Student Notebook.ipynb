{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to answering the bolded questions on Coursera, also attach your notebook, both as\n",
    "`.ipynb` and `.html`.\n",
    "\n",
    "You are the founder of a company that is looking to enter two new industries: the auto industry and the food industry. To compare the projects, your investors would like to see MVPs (Minimum Viable Products) (click [here](https://en.wikipedia.org/wiki/Minimum_viable_product) for more info) for each. You must, in one week’s time, prove that the machine learning capabilities work in both projects. Using your extensive knowledge of data science, you decide that the best model for both projects is SVM (Support Vector Machines). Therefore, you must fit SVMs for both projects and demonstrate their efficacy.\n",
    "\n",
    "In this assignment, we will be using PennGrader, a Python package built by a former TA for autograding Python notebooks. PennGrader was developed to provide students with instant feedback on their answer. You can submit your answer and know whether it's right or wrong instantly. We then record your most recent answer in our backend database. You will have 100 attempts per test case, which should be more than sufficient.\n",
    "\n",
    "<b>NOTE：Please remember to remove the </b>\n",
    "\n",
    "```python\n",
    "raise notImplementedError\n",
    "```\n",
    "<b>after your implementation, otherwise the cell will not compile.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Set Up\n",
    "Meet our old friend - PennGrader! Fill in the cell below with your PennID and then run the following cell to initialize the grader.\n",
    "\n",
    "<font color='red'>Warning:</font> Please make sure you only have one copy of the student notebook in your directory in Codio upon submission. The autograder looks for the variable `STUDENT_ID` across all notebooks, so if there is a duplicate notebook, it will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLEASE ENSURE YOUR STUDENT_ID IS ENTERED AS AN INT (NOT A STRING). IF NOT, THE AUTOGRADER WON'T KNOW WHO \n",
    "#TO ASSIGN POINTS TO YOU IN OUR BACKEND\n",
    "\n",
    "STUDENT_ID = 88888888                   # YOUR 8-DIGIT PENNID GOES HERE\n",
    "STUDENT_NAME = \"FirstName LastName\"     # YOUR FULL NAME GOES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import penngrader.grader\n",
    "\n",
    "grader = penngrader.grader.PennGrader(homework_id = 'ESE542_Online_Su_2021_HW8', student_id = STUDENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the relevant Python packages here\n",
    "# Feel free to import any other packages for this project\n",
    "\n",
    "#Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: The Auto Business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the data is vital in any study, as we do not want to mix up categorial with numerial data.\n",
    "\n",
    "This dataset has 9 variables:\n",
    "    \n",
    "| Variable | Description |\n",
    "| --- | --- | \n",
    "| <b> mpg </b> | miles per gallon |\n",
    "| <b> cylinders </b> | Number of cylinders between 4 and 8 |\n",
    "| <b> displacement </b> | Engine displacement (cu. inches) |\n",
    "| <b> horsepower </b> | Engine horsepower |\n",
    "| <b> weight </b> | Vehicle weight (lbs.) |\n",
    "| <b> acceleration </b> | Time to accelerate from 0 to 60 mph (sec.) |\n",
    "| <b> year </b> | Model year (modulo 100) |\n",
    "| <b> origin </b> | Origin of car (1. American, 2. European, 3. Japanese) |\n",
    "| <b> name </b> | Vehicle name |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Auto.csv').copy() #import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <b>What is the range of ‘year’?</b> Storre your solution in `yr_range` as (min_year, max_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-3d2788deae52>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-3d2788deae52>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    yr_range = ( ,  )\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "yr_range = ( ,  )\n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_year_range', answer = yr_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a binary output variable that takes on a $1$ for cars with gas mileage above the median, and a $0$ for cars with gas mileage below the median. Name this column `above_median`, append this column to your `data` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_median = \n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_ab_median', answer = above_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit a Support Vector Classiﬁer to the data with the default total slack budget (cost value), $C$ of $1.0$ and a <b>linear kernel</b>, in order to predict whether a car gets high or low gas mileage (i.e., the binary variable from Step 2). Find the accuracy of your model using one trial of 5-fold cross validation with `random_state=22`. Comment on your results and back up your assertions with plots. Store the test accuracy score using 5-fold cross validation in `k_fold_accuracy`.\n",
    "\n",
    "*Hint*: Do not use 'name' or 'mpg' as predictors. Also remember to standardize your data using `sklearn.preprocessing.scale` before employing SVC. To calculate the accuracy of your model, use the <b>averaged</b> `cross_val_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_accuracy = \n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_SVC', answer = k_fold_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Fit a Support Vector Classiﬁer to the data with total slack budget (cost values), $C$ of $\\{0.001, 0.01, 0.1, 1\\}$ in order to predict whether a car gets high or low gas mileage. Report the accuracy of your model using 10 trials of 5-fold cross validation with `random_state=trial` (the trial number currently running in the for-loop) and `gamma='auto'` for each of the cost values. Create a variable named `accuracies` which contains the mean accuracy of each of your four cost values. Comment on your results and back up your assertions with plots. Store the best-performing $C$ in `C_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vary the cost value for linear SVC\n",
    "cost_values = [0.001, 0.01, 0.1, 1] #Try these for now, add different values if time allots\n",
    "C_best = ''  # Enter a number\n",
    "accuracies = []\n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_SVC_tune', answer = (accuracies, C_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repeat the process in Part A Step 4, this time using SVMs with radial (rbf) basis kernels, with diﬀerent values of gamma, and cost. Store your best-performing parameters in `radial_best_params`; store your test accuracy using best performing parameters in`radial_score`. Use the following parameters for your search:\n",
    "\n",
    "    - Slack budget/Cost value:  {0.001,0.01,0.1,1,1.25,1.5,1.75,2,2.25,2.5,2.75,3,10} \n",
    "    - Gamma:  {0.001,0.025,0.05,0.075,0.1,0.125,0.15,0.2,1} \n",
    "    - Cross validation: 5-fold\n",
    "    - Scoring: ‘accuracy’\n",
    "    - kernel: 'rbf'\n",
    "\n",
    "*Hint*: Familiarize yourself with GridSearchCV. Because tuning non-linear SVMs take a long time, GridSearchCV will efficiently tune these parameters for your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 10]\n",
    "gammas = [0.001, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radial_best_params = \n",
    "radial_score = \n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_radial_gsCV', answer = (radial_best_params, radial_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Similar with question 5, but this time use a polynomial('poly') kernel instead. Store the best-performing parameters and test accuracy within `poly_best_params` and `poly_score`. Use the following parameters for your search:\n",
    "\n",
    "    - Slack budget/Cost value:  {0.001,0.01,0.1,1,1.25,1.5,1.75,2,2.25,2.5,2.75,3,10} \n",
    "    - Gamma:  {0.001,0.025,0.05,0.075,0.1,0.125,0.15,0.2,1} \n",
    "    - Degree:  {0.5,1,2,3,4,5} , only used for polynomial kernel\n",
    "    - Cross validation: 5-fold\n",
    "    - Scoring: ‘accuracy’\n",
    "    - kernel: 'poly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 10]\n",
    "gammas = [0.001, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 1]\n",
    "degrees = [0.5, 1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': Cs, 'gamma' : gammas, 'degree': degrees}\n",
    "poly_best_params = \n",
    "poly_score = \n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_poly_gsCV', answer = (poly_best_params, poly_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Comment on your overall observations. Would this MVP be satisfactory for your investors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: The Food Business\n",
    "\n",
    "Your second idea is an app that classifies images: SeeFood. For your MVP, you decide to show your Silicon Valley investors an app that classifies food images as ‘hot dog’ or ‘not hot dog’—an \\$8 million opportunity indeed<sup>1</sup>. To build this app, you have collected the following sample food images from the Food101 dataset:\n",
    "\n",
    "- 325 training images labeled  'hot dog'\n",
    "- 300 training images labeled  'not hot dog'\n",
    "- 40 test images labeled  'hot dog'\n",
    "- 35 test images labeled  'not hot dog'\n",
    "\n",
    "Your goal is to build a model that correctly labels the test images. From your experience working on the Auto MVP, you decide to use a polynomial SVM model for this project; however, due to time limitations, you decide not to tune your SVM.\n",
    "\n",
    "<sup>1</sup> To read about the data science behind how the show Silicon Valley built this app, read [this Medium article](https://medium.com/@timanglade/how-hbos-silicon-valley-built-not-hotdog-with-mobile-tensorflow-keras-react-native-ef03260747f3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the `get_data()` method below, first convert the image data into `Numpy` arrays.\n",
    "\n",
    "If the below cell fails, enter the code (without !) into the codio terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "def get_data(dir):\n",
    "    \n",
    "    images = []\n",
    "    data = []\n",
    "\n",
    "    categories = ['not_hot_dog', 'hot_dog']\n",
    "    for category in categories:\n",
    "        path = os.path.join(dir, category) # Parse the path\n",
    "        label = categories.index(category) # 1 for hot_dog\n",
    "\n",
    "        for file in os.listdir(path): # For each image\n",
    "            filepath = os.path.join(path, file)\n",
    "            img = Image.open(filepath)\n",
    "            resized_img = img.resize((100,100), Image.ANTIALIAS) # Resize to 100x100\n",
    "            img_array = np.array(resized_img).flatten() # Flatten the array to 1D\n",
    "            data.append([img_array, label]) # Append the image's array with its label\n",
    "            images.append(resized_img) # Save the images so they can be opened later\n",
    "    \n",
    "    return data, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = \n",
    "y_train = \n",
    "X_test = \n",
    "y_test = \n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_train', answer = (len(X_train), len(X_train[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_test', answer = (len(X_test), len(X_test[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Standardize `X_train` and `X_test` using `sklearn.preprocessing.scale`, in preparation for applying SVM. Hint: Scale each image individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = \n",
    "X_test =\n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_scale', answer = (np.sum(X_train[:10]), np.sum(X_test[:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit a polynomial SVM on your training data with all default parameters. Report the accuracy of the model as `training_accuracy` and `test_accuracy`. Define the predicted values as `y_pred_train` and `y_pred_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = \n",
    "test_accuracy = \n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_SVC2', answer = (training_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What are the confusion matrices for both the training set and the test set, store them in `train_confusion` and `test_confusion`? What is the True Positive Rate for the test set, store your answer in `TP_test`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_confusion = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_train_confu', answer = train_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_confusion = \n",
    "TP_test = \n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_test_score', answer = (test_confusion, TP_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Plot the ROC curve for your model using the `plot_roc()` method below. Comment on your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict(X_test))\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot here and leave comments\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Encode the predicated values as ‘hot_dog’ for ‘1’ and ‘not_hot_dog’ for ‘0’. Using the show_images() method below, show your results for both your training set and your test set, with the title of each image being your predicted value. Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_encoded = \n",
    "y_pred_test_encoded = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(image_array, labels):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import gridspec\n",
    "\n",
    "    size = len(image_array)\n",
    "    index = 1\n",
    "    fig = plt.figure(figsize=(20,100))\n",
    "    \n",
    "    for image in image_array:\n",
    "        fig.add_subplot(int(size/5), 5, index)\n",
    "        plt.imshow(image)\n",
    "        plt.title(labels[index-1])\n",
    "        plt.axis('off')\n",
    "        index += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(train_images, y_pred_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_images(test_images, y_pred_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment on your observations\n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many methods used to simplify images; to improve our classification, we are going to explore one of the feature descriptors used commonly in computer vision and image processing for object detection. Histogram of oriented gradients, or HOG, is a feature descriptor often used to extract features from image data. It works similarly to edge detection, with an added dimension of being able to detect edge directions. The image is broken down into ‘localized’ regions and the gradients and orientation are calculated. The actual implementation of the calculations can be found online; for the purpose of this analysis, we are just going to utilize prebuilt functions to aid our classification.\n",
    "\n",
    "The code below takes in an image filepath and generates both the original image, as well as the hog image.\n",
    "\n",
    "You may need to install `skimage`:\n",
    "\n",
    "```\n",
    "pip install scikit-image --user\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hogimage_example(filepath):\n",
    "    try:\n",
    "        import skimage\n",
    "        from skimage import io\n",
    "        import matplotlib.pyplot as plt\n",
    "        from skimage.color import rgb2gray\n",
    "        from skimage.transform import resize\n",
    "        from skimage.feature import hog\n",
    "    except Exception:\n",
    "        print(\"Need to install packages\")\n",
    "\n",
    "    img = io.imread(filepath) # Read in image\n",
    "    grayscale = rgb2gray(img) # Convert to grayscale to flatten to 1D\n",
    "    image_resized = resize(grayscale, (100,100),anti_aliasing=True) #Resize to 100x100\n",
    "\n",
    "    hog_features, hog_image = hog(image_resized,\n",
    "                                  visualize=True,\n",
    "                                  block_norm='L2-Hys',\n",
    "                                  pixels_per_cell=(16, 16)) # Generate hog features as well as the image\n",
    "    plt.figure()\n",
    "    plt.imshow(img) # Show the original image\n",
    "    plt.figure()\n",
    "    plt.imshow(hog_image,cmap='gray') #Show the transformed image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use the relevant parts of the above example syntax to modify the previous `get_data()` function to store the hog_features of each image. Remeber to tandardize `X_train` and `X_test` using `sklearn.preprocessing.scale`, in preparation for applying SVM. Hint: Scale each image individually.\n",
    "\n",
    "*Hint*: Don't forget to import necessary packages! Your function should return (\\[list of features, labels\\], flattened_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages \n",
    "\n",
    "# Define your function\n",
    "def get_hog_data(dir):\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = \n",
    "y_train = \n",
    "X_test = \n",
    "y_test =\n",
    "\n",
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_hog_data', answer = (X_train[0], X_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Repeat the previous SVM steps, except now using hog_features. What is the new training and test accuracy? Report the accuracy of the model as `hog_training_accuracy` and `hog_test_accuracy`. Set `random_state=22`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_training_accuracy = \n",
    "hog_test_accuracy = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.grade(test_case_id = 'test_SVC_hog', answer = (hog_training_accuracy, hog_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is not graded. Plot ROC curve using `plot_roc()` function given above. Similar with question B.6, label your testing set and show testing set images using `show_image()`. How the model built from hog_features differ from the previous model? Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise notImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real life applications, it is helpful to explore and learn how to implement existing packages that can be used to aid in analysis. There exist other methods of image simplification that can be explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: The One Billion Dollar Decision\n",
    "\n",
    "The following questions are optional and ungraded, but are interesting to think about: \n",
    "\n",
    "1. Which of the two projects should your company pursue? Why?\n",
    "2. Constant iteration is needed for a product to improve. How would you improve upon these projects in preparation for the launch of your startup?\n",
    "3. Pitch your company to investors. What is unique about your project(s)? Did you use any special preprocessing methods or models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
